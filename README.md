# GCP Data Ingestion Pipeline (Beam + Dataflow + Airflow)

This project is a serverless data ingestion pipeline built using:

- **Apache Beam** (Python)
- **Google Cloud Dataflow** (runner)
- **Cloud Storage** (input CSV)
- **BigQuery** (output)
- **Apache Airflow / Cloud Composer** (orchestration)

---

## âœ… What It Does

- Reads a CSV from GCS
- Validates records:
  - `name` is not empty
  - `email` contains `@`
  - `age` is an integer
- Writes:
  - âœ… Valid â†’ `main_table`
  - âŒ Invalid â†’ `error_table`
  - ğŸ“Š Audit log â†’ `audit_log_table`

All tables are created automatically in BigQuery.

---

## ğŸ—‚ï¸ Files

- `dataflow_dag.py`: Airflow DAG
- `dataflow_gcs_to_bq.py`: Beam pipeline script
